import cv2
import mediapipe as mp
import numpy as np
import time

# MediaPipe Handsã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
mp_hands = mp.solutions.hands
mp_drawing = mp.solutions.drawing_utils
hands = mp_hands.Hands(min_detection_confidence=0.5, min_tracking_confidence=0.5)

# Webã‚«ãƒ¡ãƒ©ã‚’é–‹ã
cap = cv2.VideoCapture(0)


def count_fingers(hand_landmarks):
    if not hand_landmarks: return 0

    # å„æŒ‡ã®å…ˆç«¯ï¼ˆæŒ‡å…ˆ: TIPï¼‰ã¨æ ¹å…ƒï¼ˆDIP, PIPï¼‰ã®åº§æ¨™
    finger_tips = [4, 8, 12, 16, 20]  # è¦ªæŒ‡, äººå·®ã—æŒ‡, ä¸­æŒ‡, è–¬æŒ‡, å°æŒ‡ã®å…ˆç«¯
    finger_dips = [3, 6, 10, 14, 18]  # å„æŒ‡ã®DIPé–¢ç¯€
    finger_mcps = [2, 5, 9, 13, 17]   # å„æŒ‡ã®MCPé–¢ç¯€

    fingers = []

    for tip, dip, mcp in zip(finger_tips[1:], finger_dips[1:], finger_mcps[1:]):  # è¦ªæŒ‡ä»¥å¤–ã®æŒ‡
        # 3æ¬¡å…ƒãƒ™ã‚¯ãƒˆãƒ«ã‚’å–å¾—
        tip_pos = np.array([hand_landmarks.landmark[tip].x, 
                           hand_landmarks.landmark[tip].y,
                           hand_landmarks.landmark[tip].z])
        dip_pos = np.array([hand_landmarks.landmark[dip].x,
                           hand_landmarks.landmark[dip].y,
                           hand_landmarks.landmark[dip].z])
        mcp_pos = np.array([hand_landmarks.landmark[mcp].x,
                           hand_landmarks.landmark[mcp].y,
                           hand_landmarks.landmark[mcp].z])

        # ãƒ™ã‚¯ãƒˆãƒ«ã‚’è¨ˆç®—
        vec1 = dip_pos - mcp_pos
        vec2 = tip_pos - dip_pos

        # è§’åº¦ã‚’è¨ˆç®—
        cos_theta = np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))
        angle = np.arccos(np.clip(cos_theta, -1.0, 1.0)) * 180 / np.pi

        if angle < 30:  # ä¿®æ­£: è§’åº¦ãŒå°ã•ã„æ™‚ï¼ˆæŒ‡ãŒä¼¸ã³ã¦ã„ã‚‹ï¼‰ã‚’1ã«ã™ã‚‹
            fingers.append(1)
        else:
            fingers.append(0)

    # è¦ªæŒ‡ã®åˆ¤å®šã‚³ãƒ¼ãƒ‰ï¼ˆã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆã‚’ä¿®æ­£ï¼‰
    thumb_tip = np.array([hand_landmarks.landmark[4].x, 
                        hand_landmarks.landmark[4].y,
                        hand_landmarks.landmark[4].z])
    thumb_ip = np.array([hand_landmarks.landmark[2].x,
                       hand_landmarks.landmark[2].y,
                       hand_landmarks.landmark[2].z])
    thumb_mcp = np.array([hand_landmarks.landmark[1].x,
                        hand_landmarks.landmark[1].y,
                        hand_landmarks.landmark[1].z])

    vec1 = thumb_ip - thumb_mcp
    vec2 = thumb_tip - thumb_ip
    cos_theta = np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))
    angle = np.arccos(np.clip(cos_theta, -1.0, 1.0)) * 180 / np.pi

    if angle < 30:
        fingers.insert(0, 1)
    else:
        fingers.insert(0, 0)

    return sum(fingers)  # returnæ–‡ã®ã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆã‚’ä¿®æ­£ï¼ˆãƒ«ãƒ¼ãƒ—å¤–ã«ç§»å‹•ï¼‰

def recognize_gesture(hand_landmarks):
    """ æŒ‡ã®æ›²ã’å…·åˆã‹ã‚‰ç°¡å˜ãªã‚¸ã‚§ã‚¹ãƒãƒ£ãƒ¼ã‚’èªè­˜ã™ã‚‹ """
    if not hand_landmarks:
        return "None"
    
    # å„æŒ‡ã®å…ˆç«¯ï¼ˆæŒ‡å…ˆ: TIPï¼‰ã¨æ ¹å…ƒï¼ˆDIP, PIPï¼‰ã®åº§æ¨™
    finger_tips = [4, 8, 12, 16, 20]  # è¦ªæŒ‡, äººå·®ã—æŒ‡, ä¸­æŒ‡, è–¬æŒ‡, å°æŒ‡ã®å…ˆç«¯
    finger_dips = [3, 6, 10, 14, 18]  # å„æŒ‡ã®DIPé–¢ç¯€

    fingers = []
    
    for tip, dip in zip(finger_tips[1:], finger_dips[1:]):  # è¦ªæŒ‡ä»¥å¤–ã®æŒ‡
        if hand_landmarks.landmark[tip].y < hand_landmarks.landmark[dip].y:  # æŒ‡ãŒä¼¸ã³ã¦ã„ã‚‹ã‹ã©ã†ã‹
            fingers.append(1)  # ä¼¸ã³ã¦ã„ã‚‹
        else:
            fingers.append(0)  # æ›²ãŒã£ã¦ã„ã‚‹

    thumb_tip = hand_landmarks.landmark[finger_tips[0]]
    thumb_ip = hand_landmarks.landmark[2]
    
    # è¦ªæŒ‡ã®æ–¹å‘ï¼ˆå³æ‰‹/å·¦æ‰‹ã‚’è€ƒæ…®ï¼‰
    if thumb_tip.x < thumb_ip.x:
        fingers.insert(0, 1)  # è¦ªæŒ‡ãŒé–‹ã„ã¦ã„ã‚‹
    else:
        fingers.insert(0, 0)  # è¦ªæŒ‡ãŒæ›²ãŒã£ã¦ã„ã‚‹

    # ã‚¸ã‚§ã‚¹ãƒãƒ£ãƒ¼èªè­˜
    if fingers == [0, 0, 0, 0, 0]:
        return "ã‚°ãƒ¼ï¼ˆâœŠï¼‰"
    elif fingers == [1, 1, 1, 1, 1]:
        return "ãƒ‘ãƒ¼ï¼ˆğŸ–ï¸ï¼‰"
    elif fingers == [0, 1, 1, 0, 0]:
        return "ãƒ”ãƒ¼ã‚¹ï¼ˆâœŒï¸ï¼‰"
    else:
        return "ä¸æ˜"

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break
    
    # ç”»åƒã‚’RGBã«å¤‰æ›
    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    result = hands.process(rgb_frame)

    finger_count = 0

    if result.multi_hand_landmarks:
        for hand_landmarks in result.multi_hand_landmarks:
            # æ‰‹ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‚’æç”»
            mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)

            # æŒ‡ã®æœ¬æ•°ã‚’æ•°ãˆã‚‹
            finger_count = count_fingers(hand_landmarks)
    
    # 2æœ¬æŒ‡ãŒæ¤œå‡ºã•ã‚ŒãŸå ´åˆã®å‡¦ç†
    if finger_count == 2:
        if two_fingers_start_time is None:
            two_fingers_start_time = time.time()
        elif time.time() - two_fingers_start_time >= 3:
            break
    else:
        two_fingers_start_time = None

    # çµæœã‚’ç”»é¢ã«è¡¨ç¤º
    cv2.putText(frame, f"Fingers: {finger_count}", (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
    cv2.imshow('MediaPipe Hands Finger Count', frame)

    # qã‚­ãƒ¼ã¾ãŸã¯ESCã‚­ãƒ¼ã§çµ‚äº†
    if cv2.waitKey(1) & 0xFF in [ord('q'), 27]:
        break

cap.release()
cv2.destroyAllWindows()
